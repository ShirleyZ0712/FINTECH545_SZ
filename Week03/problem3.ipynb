{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4be072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import cholesky\n",
    "from time import time\n",
    "file = 'DailyReturn.csv'\n",
    "data = pd.read_csv(file)\n",
    "returns_data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfac2894",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Matrix Type    Method  Time (s)  Frobenius Norm\n",
      "0   Pearson Corr + Standard Var    Direct  0.117008    7.866287e-08\n",
      "1   Pearson Corr + Standard Var  PCA 100%  0.118999    4.507415e-06\n",
      "2   Pearson Corr + Standard Var   PCA 75%  0.018006    4.507415e-06\n",
      "3   Pearson Corr + Standard Var   PCA 50%  0.026003    4.507415e-06\n",
      "4         Pearson Corr + EW Var    Direct  0.099995    1.800771e-07\n",
      "5         Pearson Corr + EW Var  PCA 100%  0.106998    1.132394e-05\n",
      "6         Pearson Corr + EW Var   PCA 75%  0.024995    1.132394e-05\n",
      "7         Pearson Corr + EW Var   PCA 50%  0.020982    1.132394e-05\n",
      "8        EW Corr + Standard Var    Direct  0.085996    6.882756e-11\n",
      "9        EW Corr + Standard Var  PCA 100%  0.113998    6.365738e-09\n",
      "10       EW Corr + Standard Var   PCA 75%  0.025997    6.365738e-09\n",
      "11       EW Corr + Standard Var   PCA 50%  0.021002    6.365738e-09\n",
      "12             EW Corr + EW Var    Direct  0.114001    3.073945e-04\n",
      "13             EW Corr + EW Var  PCA 100%  0.118000    1.354788e-02\n",
      "14             EW Corr + EW Var   PCA 75%  0.026023    1.354792e-02\n",
      "15             EW Corr + EW Var   PCA 50%  0.025034    1.354791e-02\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Step 1: Generate Pearson and Exponentially Weighted Covariance Matrices\n",
    "def pearson_correlation(returns):\n",
    "    return np.corrcoef(returns.T)\n",
    "\n",
    "def exponentially_weighted_covariance_matrix(returns, lambd=0.97):\n",
    "    T, N = returns.shape\n",
    "    cov_matrix = np.zeros((N, N))\n",
    "    weights = np.array([(1 - lambd) * lambd**(T - t - 1) for t in range(T)])\n",
    "    weights /= weights.sum()  # Normalize the weights\n",
    "    mean_returns = np.average(returns, axis=0, weights=weights)\n",
    "    \n",
    "    for t in range(T):\n",
    "        diff = (returns[t, :] - mean_returns).reshape(-1, 1)\n",
    "        cov_matrix += weights[t] * (diff @ diff.T)\n",
    "    \n",
    "    return cov_matrix\n",
    "\n",
    "# Step 2: PCA Simulation\n",
    "def pca_simulation(cov_matrix, mean_returns, explained_variance=None, num_simulations=25000):\n",
    "    if explained_variance is not None:\n",
    "        pca = PCA()\n",
    "        pca.fit(cov_matrix)\n",
    "        cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "        components_to_keep = np.searchsorted(cumulative_variance, explained_variance) + 1\n",
    "        eigvals = pca.explained_variance_[:components_to_keep]\n",
    "        eigvecs = pca.components_[:components_to_keep]\n",
    "        L = eigvecs.T @ np.diag(np.sqrt(eigvals))\n",
    "    else:\n",
    "        L = cholesky(cov_matrix, lower=True)\n",
    "    \n",
    "    Z = np.random.normal(size=(L.shape[1], num_simulations))\n",
    "    simulated_returns = L @ Z + mean_returns[:, np.newaxis]\n",
    "    \n",
    "    return simulated_returns\n",
    "\n",
    "# Step 3: Frobenius Norm calculation\n",
    "def frobenius_norm(matrix1, matrix2):\n",
    "    return np.linalg.norm(matrix1 - matrix2, 'fro')\n",
    "\n",
    "# Step 4: Run all simulations and compare\n",
    "def run_simulation_and_compare(returns_data):\n",
    "    pearson_corr = pearson_correlation(returns_data)\n",
    "    ew_cov_matrix = exponentially_weighted_covariance_matrix(returns_data)\n",
    "    \n",
    "    pearson_var = np.var(returns_data, axis=0)\n",
    "    ew_var = np.diag(ew_cov_matrix)\n",
    "    \n",
    "    cov_matrices = {\n",
    "        'Pearson Corr + Standard Var': np.diag(pearson_var) @ pearson_corr @ np.diag(pearson_var),\n",
    "        'Pearson Corr + EW Var': np.diag(ew_var) @ pearson_corr @ np.diag(ew_var),\n",
    "        'EW Corr + Standard Var': np.diag(pearson_var) @ ew_cov_matrix @ np.diag(pearson_var),\n",
    "        'EW Corr + EW Var': ew_cov_matrix\n",
    "    }\n",
    "    \n",
    "    flattened_results = []\n",
    "    for name, cov_matrix in cov_matrices.items():\n",
    "        mean_returns = np.mean(returns_data, axis=0)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        direct_sim = pca_simulation(cov_matrix, mean_returns)\n",
    "        direct_time = time.time() - start_time\n",
    "        direct_sim_cov = np.cov(direct_sim)\n",
    "        direct_frobenius = frobenius_norm(cov_matrix, direct_sim_cov)\n",
    "        \n",
    "        flattened_results.append({\n",
    "            'Matrix Type': name,\n",
    "            'Method': 'Direct',\n",
    "            'Time (s)': direct_time,\n",
    "            'Frobenius Norm': direct_frobenius\n",
    "        })\n",
    "        \n",
    "        pca_variances = [1.0, 0.75, 0.5]\n",
    "        for var_explained in pca_variances:\n",
    "            start_time = time.time()\n",
    "            pca_sim = pca_simulation(cov_matrix, mean_returns, explained_variance=var_explained)\n",
    "            pca_time = time.time() - start_time\n",
    "            pca_sim_cov = np.cov(pca_sim)\n",
    "            pca_frobenius = frobenius_norm(cov_matrix, pca_sim_cov)\n",
    "            \n",
    "            flattened_results.append({\n",
    "                'Matrix Type': name,\n",
    "                'Method': f'PCA {int(var_explained * 100)}%',\n",
    "                'Time (s)': pca_time,\n",
    "                'Frobenius Norm': pca_frobenius\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(flattened_results)\n",
    "\n",
    "simulation_results_df = run_simulation_and_compare(returns_data)\n",
    "\n",
    "print(simulation_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
